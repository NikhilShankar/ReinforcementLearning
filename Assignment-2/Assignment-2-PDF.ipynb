{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assignment-2**\n",
    "**Reinforcement Learning Programming - CSCN 8020**\n",
    "Submitted by : \n",
    "- Nikhil Shankar C S\n",
    "- 9026254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Methodology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comparing different hyper parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So we need to try 4 different learning rates and 3 different exploration factors.\n",
    "- To understand about the influence of discount factor we are using two discount factors as well.\n",
    "- So in total we will try 3 * 4 * 2 ( 24 ) different models and evaluate them based on the Total Steps and Total Rewards, Average Rewards, Average Steps and Training Time during simulation after training.\n",
    "- In order to do the evaluation correctly we need to make sure that the evaluation happens for a good amount of iterations. So we would simulate around 50 episodes for each model after training and take average of the rewards and steps taken to evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Results after training 24 models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image](24ModelCombinationResults.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best one in terms of Average steps taken**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image 2](BestOf24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that Learning Rate of 0.2 | Discount Factor of 0.8 | Exploration Factor of 0.1 gave the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image 3](24ModelsGraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that from the above graph it is evident that as learnig rate went below 0.1 it was exhibiting worse results in terms of rewards and average steps taken.\n",
    "- We can also see that the number of Completed steps (green bar) were really low while for LR 0.1 and 0.2 all episodes reached a completed state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Comparsion between Learning Rate 0.1 and 0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image 6](Best2ModelsGraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Some Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning rate has a sweet spot for all problems. Meaning very low learning rate and very large learning rate can be decremental in finding the optimal solution due to missing local minimums or getting stuck in local minimum respectively.\n",
    "- We can see that as the Learning rate was lowered below 0.1 to 0.01 and then to 0.001 the results kept becoming worse as shown by the negative axis blue lines in the first graph.\n",
    "- From the table and graph above we can see that both **Learning rates 0.1 and 0.2** gives very good results. Both were able to solve the problem in identical average reward and average steps. \n",
    "-  We can also see that training time is slightly less for learning rate 0.2.\n",
    "- We can also see that average steps and average rewards are better when we have lower exploration factor. ie for same learning rate and discount factor keeping the exploration factor low gave us better results. \n",
    "- We can also see that discount factor when it is lowered from 0.9 to 0.8 it performs worse on average steps taken which means increasing the discount factor is better for solving the problem in minimum number of steps. Also a lower discount rate requires more time to train the model.\n",
    "\n",
    "- To Summarize if we give prime importance to average steps taken which aligns with a realworld taxi problem we should select the following hyper parameters.\n",
    "- **Learning Rate : 0.2  | Discount Factor : 0.8 | Exploration Factor : 0.1** = **Avg Steps = 14.02** gave the best result in terms of average steps taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Final Stage**\n",
    "\n",
    "- We have experimented with 3 different hyper parameters and we have one more hyper parameter we can test the best model against which is the number of episodes used for training. \n",
    "- The above results were for 5000 episode training.\n",
    "- Now we will try with 250, 2000, 5000 & 10000 training episode respectively and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image 5](FinalBestModel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image 6](FinalBestModel-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LocalImage 7](FinalBestModelTraining.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With various amount of training episode values we have found some interesting insights again.\n",
    "- Its not necessary as we train the model more we find a better solution.\n",
    "- Specifically in our case 250 training sessions proved useless because only 7 out of 50 completed the task. However the interesting thing is that  2000 training episode gave the best result as opposed to 5000 and 10000 training episodes.\n",
    "- It means that an optimal training episode is somewhere between 250 - 2000.\n",
    "\n",
    "- The average steps taken for the best model is : 14.82 and average reward is ~2.4 and training time is : 1.1 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classical_ml_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
